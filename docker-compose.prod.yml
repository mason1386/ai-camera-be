services:
  # --- INFRASTRUCTURE ---
  postgres:
    image: postgres:15-alpine
    container_name: aic_prod_postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-aic_admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-aic_secure_prod_pass}
      POSTGRES_DB: ${POSTGRES_DB:-ai_camera_prod}
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
    networks:
      - aic_prod_net

  redis:
    image: redis:7-alpine
    container_name: aic_prod_redis
    restart: always
    volumes:
      - redis_data_prod:/data
    networks:
      - aic_prod_net

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: aic_prod_zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - aic_prod_net

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: aic_prod_kafka
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - aic_prod_net

  # --- APPLICATION ---
  
  # Job run migration once
  migration:
    build: .
    container_name: aic_prod_migration
    depends_on:
      - postgres
    command: ["./migration"]
    environment:
      - SERVER_ENV=production
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_USER=${POSTGRES_USER:-aic_admin}
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-aic_secure_prod_pass}
      - DATABASE_DBNAME=${POSTGRES_DB:-ai_camera_prod}
      - DATABASE_SSLMODE=disable
    networks:
      - aic_prod_net

  api:
    build: .
    container_name: aic_prod_api
    restart: always
    depends_on:
      migration:
        condition: service_completed_successfully
      postgres:
        condition: service_started
      redis:
        condition: service_started
      kafka:
        condition: service_started
    ports:
      - "8080:8080"
    environment:
      - SERVER_ENV=production
      - SERVER_PORT=8080
      # DB prefix DATABASE_
      - DATABASE_HOST=postgres
      - DATABASE_PORT=5432
      - DATABASE_USER=${POSTGRES_USER:-aic_admin}
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-aic_secure_prod_pass}
      - DATABASE_DBNAME=${POSTGRES_DB:-ai_camera_prod}
      - DATABASE_SSLMODE=disable
      # Redis prefix REDIS_
      - REDIS_ADDR=redis:6379
      - REDIS_PASSWORD=
      - REDIS_DB=0
      # Kafka prefix KAFKA_
      # Note: config.yaml uses "brokers" (string array), viper handles KAFKA_BROKERS as space separated string if configured, 
      # but simplistic unmarshal might fail for slice.
      # Safest way for slice: usually VIPER is tricky with slices via Env. 
      # Let's keep it simple for now or assume user mounts config.yaml.
      # However, let's try to map it correctly.
    networks:
      - aic_prod_net

  worker:
    build: .
    container_name: aic_prod_worker
    restart: always
    depends_on:
      api:
        condition: service_started
    command: ["./worker"]
    environment:
      - SERVER_ENV=production
      - DATABASE_HOST=postgres
      - DATABASE_USER=${POSTGRES_USER:-aic_admin}
      - DATABASE_PASSWORD=${POSTGRES_PASSWORD:-aic_secure_prod_pass}
      - DATABASE_DBNAME=${POSTGRES_DB:-ai_camera_prod}
      - REDIS_ADDR=redis:6379
    networks:
      - aic_prod_net

volumes:
  postgres_data_prod:
  redis_data_prod:

networks:
  aic_prod_net:
    driver: bridge
